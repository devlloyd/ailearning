<!DOCTYPE html>
<head>
    <meta charset="utf-8">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
        }
        .tooltip {
            cursor: pointer;
        }
        .collapse-content {
            display: none;
            margin-left: 1em;
        }

        .collapse-title::after {
            content: " ▶";
        }

        .active::after {
            content: " ▼";
        }
    </style>
    <script>
        function toggleCollapse(event) {
            var row = event.target.parentElement.parentElement;
            var contents = row.getElementsByClassName("collapse-content");
            event.target.classList.toggle("active");
            for (var i = 0; i < contents.length; i++) {
                if (contents[i].style.display === "block") {
                    contents[i].style.display = "none";
                } else {
                    contents[i].style.display = "block";
                }
            }
        }
    </script>
</head>


<body>
<h2> A Timeline of AI Research Papers </h2>
<script src="https://d3js.org/d3.v5.min.js"></script>
<script>

// Set the dimensions of the canvas / graph
var margin = {top: 30, right: 20, bottom: 30, left: 50},
    width = 1200 - margin.left - margin.right,
    height = 500 - margin.top - margin.bottom;

// Set the ranges
var x = d3.scaleTime().range([0, width]);
var y = d3.scalePoint().range([0, height]);

// Define the axes
var xAxis = d3.axisBottom(x).ticks(5);

// Adds the svg canvas
var svg = d3.select("body")
    .append("svg")
        .attr("width", width + margin.left + margin.right)
        .attr("height", height + margin.top + margin.bottom)
    .append("g")
        .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

// Create a tooltip
var tooltip = d3.select("body").append("div")
    .attr("class", "tooltip")
    .style("opacity", 0)
    .style("position", "absolute")
    .style("background-color", "white")
    .style("border", "solid")
    .style("border-width", "1px")
    .style("border-radius", "5px")
    .style("padding", "10px")
    .style("cursor", "pointer");  // Change cursor to pointer on hover

// Get the data
var data = [
    {event: "Generative Adversarial Networks", year: "2014", link: "https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf", description: "todo"},
    {event: "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems", year: "2016", link: "https://arxiv.org/abs/1603.04467", description: "todo"},
    {event: "Attention is All You Need", year: "2017", link: "https://arxiv.org/pdf/1706.03762.pdf", description: "Introduced the concept of attention in neural networks."},
    {event: "Deep reinforcement learning from human preferences", year: "2017", link: "https://arxiv.org/pdf/1706.03741.pdf", description: "introduced a way for computer programs to learn complex tasks by getting feedback from humans, rather than relying on predefined goals"},
    {event: "Equivalence Between Policy Gradients and Soft Q-Learning", year: "2017", link: "https://arxiv.org/pdf/1704.06440.pdf", description: "helped bridge the gap between two major approaches to reinforcement learning: value-based methods and policy-based methods"},
    {event: "Improving Language Understanding by Generative Pre-Training", year: "2018", link: "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf", description: "showed that a computer program can get better at understanding and using language by first learning from lots of text, and then fine-tuning its knowledge with specific tasks."},
    {event: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", year: "2018", link: "https://arxiv.org/abs/1810.04805", description: "todo"},
    {event: "An Empirical Model of Large-Batch Training", year: "2018", link: "https://arxiv.org/pdf/1812.06162.pdf", description: "showed that there's an optimal size for the groups of examples used to train AI models, and this size can be predicted using a measure they call the 'gradient noise scale'."},
    {event: "Scaling Laws for for Neural Language Models", year: "2020", link: "https://arxiv.org/pdf/2001.08361.pdf", description: " discovered that the performance of language models improves predictably as we increase the model size, dataset size, and compute power, and that the most efficient training involves using very large models and stopping before they fully learn the dataset."},
    {event: "Language Models are Few-Shot Learners", year: "2020", link: "https://arxiv.org/pdf/2005.14165.pdf", description: "Showed that big language models can learn to do a variety of tasks well with just a few examples"},
    {event: "High-Resolution Image Synthesis with Latent Diffusion Models", year: "2021", link: "https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf", description: "responsible for stable diffusion"},   
];

data.forEach(function(d) {
    d.year = new Date(d.year);
});

// Scale the range of the data
x.domain([new Date("2014"), new Date("2023")]);
y.domain(data.map(function(d) { return d.event; }));

// Add lines from points to the timeline
svg.selectAll("line")
    .data(data)
  .enter().append("line")
    .attr("x1", function(d) { return x(d.year); })
    .attr("y1", height/2)
    .attr("x2", function(d) { return x(d.year); })
    .attr("y2", function(d) { return d.event == "Improving Language Understanding by Generative Pre-Training" ? y(d.event) + 30 : y(d.event); }) // Changed from 20 to 30
    .attr("stroke", "black")

// Add labels to the scatterplot points
svg.selectAll(".text")
    .data(data)
  .enter().append("text")
    .attr("x", function(d) { return x(d.year); })
    .attr("y", function(d) { return d.event == "Improving Language Understanding by Generative Pre-Training" ? y(d.event) + 30 : y(d.event); }) // Changed from 20 to 30
    .text(function(d) { return d.event; })
    .attr("font-size", "10px")
    .attr("dx", "10px");

// Add the X Axis
svg.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0," + height/2 + ")")
    .call(xAxis);

// Add dots to the scatterplot
var outerDots = svg.selectAll("dot")
    .data(data)
    .enter().append("circle")
    .attr("r", 10) // Increase the radius for the outer circle
    .attr("cx", function(d) { return x(d.year); })
    .attr("cy", function(d) { return d.event == "Improving Language Understanding by Generative Pre-Training" ? y(d.event) + 30 : y(d.event); }) 
    .attr("fill", "white")
    .attr("stroke", "black"); // Add a stroke to make the outer circle visible

var dots = svg.selectAll("dot")
    .data(data)
    .enter().append("circle")
    .attr("r", 5)
    .attr("cx", function(d) { return x(d.year); })
    .attr("cy", function(d) { return d.event == "Improving Language Understanding by Generative Pre-Training" ? y(d.event) + 30 : y(d.event); }) // Changed from 20 to 30
    .attr("fill", "red")
    .on("mouseover", function(d) {
    	tooltip.transition()
    	.duration(200)
    	.style("opacity", .9);
   	 tooltip.html('<a href="' + d.link + '" target="_blank">Link to paper</a><br>' + d.description)
   	 .style("left", (d3.event.pageX + 5) + "px")
    	.style("top", (d3.event.pageY - 28) + "px");})

    .on("mouseout", function(d) {
        tooltip.transition()
        .duration(2000)
        .style("opacity", 0);
    });

</script>

<div style="margin-top: 20px; padding: 10px; border: 1px solid black; width: 80%; margin-left: auto; margin-right: auto; border-radius: 10px;">
    <h2>Tip:</h2>
    <p>You can use <a href="https://chat.openai.com" target="_blank">ChatGPT</a> to help with understanding these papers.</p>
    <p>Example prompts (click to copy):</p>
   <p class="copy-text" onclick="copyToClipboard(this, 'copy-notification')">&#128203; I am a recruiter at a top AI research lab. As a recruiter, I do not have a technical background, and have some trouble understanding the heavy language used in AI research papers. However, it is important for me to understand the fundamentals of AI for my job. Can I provide you a paper, and you summarize each section in a way that is similar to an "explain like I'm 5" (ELI5) explanation?</p>

<p class="copy-text" onclick="copyToClipboard(this, 'copy-notification')">&#128203; Can you give me each section but in plain language that a young adult might understand?</p>

<p class="copy-text" onclick="copyToClipboard(this, 'copy-notification')">&#128203; Can you give me the primary takeaway of the paper, in plain language?</p>

<p> It is encouraged that you ask questions as you go along about anything you are unclear on. You'll likely be surprised how ambiguous questions are understood, and clarified. </p>

</div>

<div id="copy-notification" style="display: none; position: fixed; top: 20px; left: 50%; transform: translateX(-50%); background-color: #ddd; padding: 10px; border-radius: 5px;">Text Copied!</div>


<script>
function copyToClipboard(element, popupId) {
  var text = element.innerText;
  var input = document.createElement('input');
  input.setAttribute('value', text);
  document.body.appendChild(input);
  input.select();
  var result = document.execCommand('copy');
  document.body.removeChild(input)

  if (result) {
    var popup = document.getElementById(popupId);
    popup.style.display = "block"; // make the popup visible
    setTimeout(function() {
      popup.style.display = "none"; // hide the popup after 2 seconds
    }, 2000);
  }

  return result;
}

</script>


</body>

<h2>Example: 'Attention is All You Need' explained by ChatGPT, two ways</h2>



<table style="width:100%; border-collapse: collapse;" border="1">
  <tr>
    <th>ELI5</th>
    <th>Plain language</th>
  </tr>
  <tr>
   <td>
<div class="collapse-title active" onclick="toggleCollapse(event)">
  <b>Abstract</b>
</div>
<div class="collapse-content" style="display: block;">
Imagine you're trying to build a toy car. Instead of using lots of different parts like wheels, axles, and gears, you find a way to build it using only Lego blocks. This is what the authors of the paper did with a type of computer program called a Transformer. It's simpler, works better, and is faster to build than other types of programs.
</div>
</td>
    <td>
<div class="collapse-title active" onclick="toggleCollapse(event)">
  <b>Abstract</b>
</div>
<div class="collapse-content" style="display: block;">


The paper introduces a new network architecture called the Transformer, which is based solely on attention mechanisms, eliminating the need for recurrent or convolutional neural networks. The Transformer performs better in quality, is more parallelizable, and requires less time to train than other models. It has been successfully applied to machine translation tasks and English constituency parsing.
</td>
  </tr>
  <tr>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>1. Introduction</b>
        </div>
        <div class="collapse-content">
Think of a line of dominoes. You can't knock them all over at once; you have to start at one end and go one by one. This is how some computer programs work, and it can be slow. The authors made a new program, the Transformer, that doesn't have to go one by one. It can look at all the dominoes at the same time.
</td>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>1. Introduction</b>
        </div>
        <div class="collapse-content">
The paper discusses the limitations of recurrent neural networks (RNNs), particularly their sequential nature which prevents parallelization within training examples. The authors propose the Transformer as a solution, which relies entirely on an attention mechanism to draw global dependencies between input and output.
</td>
  </tr>
  <tr>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>2. Background</b>
        </div>
        <div class="collapse-content">
There are other ways to knock over all the dominoes at once, like using a big ruler to knock them over. But sometimes, the ruler doesn't reach all the dominoes, especially if they're far apart. The Transformer is like having a magic ruler that can stretch to reach any domino, no matter how far.
</td>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>2. Background</b>
        </div>
        <div class="collapse-content">
The authors discuss other models that aim to reduce sequential computation, such as the Extended Neural GPU, ByteNet, and ConvS2S, which use convolutional neural networks. However, these models still have limitations in learning dependencies between distant positions. The Transformer overcomes this by using self-attention mechanisms.

</td>
  </tr>
  <tr>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3. Model Architecture</b>
        </div>
        <div class="collapse-content">
The Transformer is like a factory with two conveyor belts (an encoder and a decoder). Each conveyor belt has several stations (layers). At each station, a worker (attention mechanism) looks at all the toys (data) on the belt at once and decides what to do next. The second conveyor belt has an extra worker who also looks at what the first conveyor belt did.

</td>
    <td>
 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3. Model Architecture</b>
        </div>
        <div class="collapse-content">
The Transformer follows an encoder-decoder structure. Both the encoder and decoder are composed of a stack of identical layers, each with two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The decoder also has a third sub-layer which performs multi-head attention over the output of the encoder stack.
</td>
  </tr>
  <tr>
    <td>

 <div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.2 Attention</b>
        </div>
        <div class="collapse-content">
Imagine you're in a classroom and the teacher asks a question. Some students (the "keys") raise their hands to answer, and the teacher (the "query") picks the best answer (the "value"). The Transformer does something similar, but it can listen to multiple teachers asking questions at the same time.
</td>
    <td>

<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.2 Attention</b>
        </div>
        <div class="collapse-content">
The paper describes the attention function as mapping a query and a set of key-value pairs to an output. The authors introduce a variant called "Scaled Dot-Product Attention". They also introduce "Multi-Head Attention" which allows the model to attend to information from different representation subspaces at different positions.
</td>
  </tr>
  <tr>
    <td>

<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.3 Position-wise Feed-Forward Networks</b>
        </div>
        <div class="collapse-content">
After the attention workers look at all the toys, there's another worker at each station. This worker takes each toy and does a special job with it. This job is the same for each toy and doesn't depend on the other toys.
</td>
    <td>
<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.3 Position-wise Feed-Forward Networks</b>
        </div>
        <div class="collapse-content">
Each layer in the encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.
</td>
  </tr>
  <tr>
    <td>
<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.4 Embeddings and Softmax</b>
        </div>
        <div class="collapse-content">
The Transformer has a special machine that turns words into Lego blocks (embeddings) that it can work with. After the Transformer is done, it uses another machine to turn the Lego blocks back into words (softmax).
</td>
    <td>
<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.4 Embeddings and Softmax</b>
        </div>
        <div class="collapse-content">
The model uses learned embeddings to convert the input tokens and output tokens to vectors. A learned linear transformation and softmax function are used to convert the decoder output to predicted next-token probabilities.
</td>
  </tr>
  <tr>
    <td>

<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.4 Positional Encoding</b>
        </div>
        <div class="collapse-content">
The Transformer needs to know the order of the words, like knowing that "cat chases mouse" is not the same as "mouse chases cat". To do this, it uses a special trick with sine and cosine, which are like special types of swings that go back and forth in a specific way.
</td>
    <td>

<div class="collapse-title" onclick="toggleCollapse(event)">
          <b>3.4 Positional Encoding</b>
        </div>
        <div class="collapse-content">
Since the model contains no recurrence and no convolution, positional encodings are added to the input embeddings to make use of the order of the sequence. The authors use sine and cosine functions of different frequencies for the positional encodings.
</td>
  </tr>
</table>

</html>

